{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md413FzAvFD8"
      },
      "source": [
        "# DX 704 Week 10 Project\n",
        "\n",
        "In this project, you will implement document search within a question and answer database and assess its performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4B2Ff6lisqH"
      },
      "source": [
        "The full project description and a template notebook are available on GitHub: [Project 10 Materials](https://github.com/bu-cds-dx704/dx704-project-10).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEezzKGSdyXB"
      },
      "source": [
        "## Example Code\n",
        "\n",
        "You may find it helpful to refer to these GitHub repositories of Jupyter notebooks for example code.\n",
        "\n",
        "* https://github.com/bu-cds-omds/dx601-examples\n",
        "* https://github.com/bu-cds-omds/dx602-examples\n",
        "* https://github.com/bu-cds-omds/dx603-examples\n",
        "* https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQhkdHNFbwLp"
      },
      "source": [
        "## Part 1: Download the SQuAD-explorer Data Set\n",
        "\n",
        "You may use the code provided below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KDN4uTycILU",
        "outputId": "263d0284-de7d-493e-c40f-92161d739ac0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'SQuAD-explorer'...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 5563, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 5563 (delta 11), reused 17 (delta 6), pack-reused 5539 (from 1)\u001b[K\n",
            "Receiving objects: 100% (5563/5563), 52.26 MiB | 29.15 MiB/s, done.\n",
            "Resolving deltas: 100% (3563/3563), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rajpurkar/SQuAD-explorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W7Cgmz-lVmBF"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kXc87YHZVsOz"
      },
      "outputs": [],
      "source": [
        "with open(\"SQuAD-explorer/dataset/train-v1.1.json\") as fp:\n",
        "    train_data = json.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaYKgEa3V149",
        "outputId": "d512a1ae-7e36-4675-c3b9-05ebea9bf9df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJrdzIqwV3FK",
        "outputId": "78415ac7-f68a-4179-cc19-6ccd18c00b33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['data', 'version']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(train_data.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbru7Z_UV74r",
        "outputId": "5c90d6d6-e0db-459e-fc99-8c59e0d7ee54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_data[\"data\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvLq8Xo_V-Ji",
        "outputId": "214682af-3013-4c9c-a344-1953dd6e7120"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "442"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_data[\"data\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIaSECnAWBv7",
        "outputId": "d9e182f7-22c8-4f9b-c756-adacde1112ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_data[\"data\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze4bVs4bWJ7l",
        "outputId": "9dc04b5a-0943-4cb2-d78b-c137545a35ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['title', 'paragraphs'])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[\"data\"][0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uIwF0bTeWMEC",
        "outputId": "357ae956-3930-418f-e822-62de93d2fcb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'University_of_Notre_Dame'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[\"data\"][0][\"title\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YopAkB-WOTW",
        "outputId": "e2767d66-e39b-40f4-bd42-47a40c9240ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_data[\"data\"][0][\"paragraphs\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Bm3BAIqWRCT",
        "outputId": "da233573-f62c-46ee-9384-16fd6a110ed3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
              " 'qas': [{'answers': [{'answer_start': 515,\n",
              "     'text': 'Saint Bernadette Soubirous'}],\n",
              "   'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
              "   'id': '5733be284776f41900661182'},\n",
              "  {'answers': [{'answer_start': 188, 'text': 'a copper statue of Christ'}],\n",
              "   'question': 'What is in front of the Notre Dame Main Building?',\n",
              "   'id': '5733be284776f4190066117f'},\n",
              "  {'answers': [{'answer_start': 279, 'text': 'the Main Building'}],\n",
              "   'question': 'The Basilica of the Sacred heart at Notre Dame is beside to which structure?',\n",
              "   'id': '5733be284776f41900661180'},\n",
              "  {'answers': [{'answer_start': 381,\n",
              "     'text': 'a Marian place of prayer and reflection'}],\n",
              "   'question': 'What is the Grotto at Notre Dame?',\n",
              "   'id': '5733be284776f41900661181'},\n",
              "  {'answers': [{'answer_start': 92,\n",
              "     'text': 'a golden statue of the Virgin Mary'}],\n",
              "   'question': 'What sits on top of the Main Building at Notre Dame?',\n",
              "   'id': '5733be284776f4190066117e'}]}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[\"data\"][0][\"paragraphs\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI7RL5JTWraU",
        "outputId": "2a09c434-6eb4-4bba-9a60-d323136cfbfe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18896"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(len(doc[\"paragraphs\"]) for doc in train_data[\"data\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8oSLkMqvMFF"
      },
      "source": [
        "## Part 2: Restructure JSON Data for Processing\n",
        "\n",
        "Parse the file \"SQuAD-explorer/dataset/train-v1.1.json\" above to produce a file \"parsed.tsv\" with columns document_title, paragraph_index, and paragraph_context.\n",
        "The paragraph_index column should be zero-indexed, so zero for the first paragraph of each document.\n",
        "Use pandas `to_csv` method to write the file since there are many quotes and other issues to handle otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJHSCtWWaLAG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "import pandas as pd\n",
        "\n",
        "parsed_rows = []\n",
        "\n",
        "for article in train_data['data']:\n",
        "    document_title = article['title']\n",
        "    \n",
        "    for paragraph_index, paragraph in enumerate(article['paragraphs']):\n",
        "        paragraph_context = paragraph['context']\n",
        "        \n",
        "        parsed_rows.append({\n",
        "            'document_title': document_title,\n",
        "            'paragraph_index': paragraph_index,\n",
        "            'paragraph_context': paragraph_context\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(parsed_rows)\n",
        "\n",
        "df.to_csv('parsed.tsv', sep='\\t', index=False, encoding='utf-8')\n",
        "\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_9VpBX7aNLP"
      },
      "source": [
        "Submit \"parsed.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H7Sr3TdcTqr"
      },
      "source": [
        "## Part 3: Prepare Suitable Paragraph Vectors for Document Search\n",
        "\n",
        "Design and implement paragraph vectors based on their text with length 1024.\n",
        "Note that this will be much smaller than the number of distinct words in the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRkun5bA1J6c"
      },
      "source": [
        "Hint: you can base your vectors on any techniques covered in this module so far.\n",
        "Beware that they will be automatically assessed (along with the question vectors of part 4) to make sure they retain useful information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v978AkFmdnLD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 18896 paragraphs\n",
            "Creating TF-IDF vectors...\n",
            "Paragraph vectors shape: (18896, 1024)\n",
            "\n",
            "Saved:\n",
            "- paragraph-vectors.tsv.gz (shape: (18896, 3))\n",
            "- tfidf_vectorizer.pkl\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pickle\n",
        "\n",
        "# Load the parsed data\n",
        "df = pd.read_csv('parsed.tsv', sep='\\t', encoding='utf-8')\n",
        "\n",
        "\n",
        "# Create TF-IDF vectors with exactly 1024 features\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=1024,\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "# Fit and transform the paragraph contexts\n",
        "paragraph_vectors = tfidf_vectorizer.fit_transform(df['paragraph_context']).toarray()\n",
        "\n",
        "print(f\"Paragraph vectors shape: {paragraph_vectors.shape}\")\n",
        "\n",
        "# Create output dataframe with vectors as JSON\n",
        "import json\n",
        "\n",
        "df['paragraph_vector_json'] = [json.dumps(vec.tolist()) for vec in paragraph_vectors]\n",
        "\n",
        "# Select only the required columns\n",
        "output_df = df[['document_title', 'paragraph_index', 'paragraph_vector_json']]\n",
        "\n",
        "# Save to compressed TSV\n",
        "output_df.to_csv('paragraph-vectors.tsv.gz', sep='\\t', index=False)\n",
        "\n",
        "# Save the vectorizer for later use with questions\n",
        "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tfidf_vectorizer, f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbZRTxludpHC"
      },
      "source": [
        "Save your paragraph vectors in a file \"paragraph-vectors.tsv.gz\" with columns document_title, paragraph_index, and paragraph_vector_json where paragraph_vector_json is a JSON encoded list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGE7ooGVckTC"
      },
      "source": [
        "Hint: don't forget the \".gz\" extension indicating gzip compression.\n",
        "The Pandas `.to_csv` method will automatically add the compression if you save data with a filename ending in \".gz\", so you just need to pass it the right filename."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71KxgBp-eeqm"
      },
      "source": [
        "Submit \"paragraph-vectors.tsv.gz\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPL_MR_GeSa1"
      },
      "source": [
        "## Part 4: Encode Question Vectors with the Same Design\n",
        "\n",
        "Read the questions in \"questions.tsv\" and encode them in the same way that you encoded the paragraph vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75F95fJjpZ3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 100 questions\n",
            "Question vectors shape: (100, 1024)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "questions_df = pd.read_csv('questions.tsv', sep='\\t', encoding='utf-8')\n",
        "\n",
        "\n",
        "with open('tfidf_vectorizer.pkl', 'rb') as f:\n",
        "    tfidf_vectorizer = pickle.load(f)\n",
        "\n",
        "question_vectors = tfidf_vectorizer.transform(questions_df['question']).toarray()\n",
        "\n",
        "questions_df['question_vector_json'] = [json.dumps(vec.tolist()) for vec in question_vectors]\n",
        "\n",
        "output_df = questions_df[['question_id', 'question_vector_json']]\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H5j32O5pb03"
      },
      "source": [
        "Save your question vectors in \"question-vectors.tsv\" with columns question_id and question_vector_json."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLyvhIcYpr06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saved:\n",
            "- question-vectors.tsv (shape: (100, 2))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "output_df.to_csv('question-vectors.tsv', sep='\\t', index=False)\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWmcWnJUptZN"
      },
      "source": [
        "Submit \"question-vectors.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pRDyTUxcvCx"
      },
      "source": [
        "## Part 5: Match Questions to Paragraphs using Nearest Neighbors\n",
        "\n",
        "Match your question vectors to paragraph vectors and identify the top 5 paragraph vectors for each question using nearest neighbors.\n",
        "Specifically, use the Euclidean distance between the vectors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "dJlB2SsMqf1F"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "\n",
        "para_df = pd.read_csv('paragraph-vectors.tsv.gz', sep='\\t', encoding='utf-8')\n",
        "para_vectors = np.array([json.loads(vec) for vec in para_df['paragraph_vector_json']])\n",
        "\n",
        "quest_df = pd.read_csv('question-vectors.tsv', sep='\\t', encoding='utf-8')\n",
        "quest_vectors = np.array([json.loads(vec) for vec in quest_df['question_vector_json']])\n",
        "\n",
        "matches = []\n",
        "\n",
        "for q_idx, question_id in enumerate(quest_df['question_id']):\n",
        "    distances = np.linalg.norm(para_vectors - quest_vectors[q_idx], axis=1)\n",
        "    \n",
        "    top_5_indices = np.argsort(distances)[:5]\n",
        "    \n",
        "    for rank, para_idx in enumerate(top_5_indices):\n",
        "        matches.append({\n",
        "            'question_id': question_id,\n",
        "            'question_rank': rank,\n",
        "            'document_title': para_df.iloc[para_idx]['document_title'],\n",
        "            'paragraph_index': para_df.iloc[para_idx]['paragraph_index']\n",
        "        })\n",
        "\n",
        "\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvjW3nP-qkSk"
      },
      "source": [
        "Save your top matches in a file \"question-matches.tsv\" with columns question_id, question_rank, document_title, and paragraph_index.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "heaNwWMlrAwv"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "matches_df = pd.DataFrame(matches)\n",
        "matches_df.to_csv('question-matches.tsv', sep='\\t', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0m-ogJjrCK8"
      },
      "source": [
        "Submit \"question-matches.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NftG5ez0tsyy"
      },
      "source": [
        "## Part 6: Spot Check Question and Paragraph Matches\n",
        "\n",
        "Review the paragraphs matched to the first 5 questions (sorted by question_id ascending).\n",
        "Which paragraph was the worst match for each question?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "QUESTION ID: 1\n",
            "Question: What was the goal of the abuse of region project?\n",
            "================================================================================\n",
            "\n",
            "Rank 0: Tuvalu (paragraph 49)\n",
            "The eastern shoreline of Funafuti Lagoon was modified during World War II when the airfield (what is now Funafuti International Airport) was constructed. The coral base of the atoll was used as fill to create the runway. The resulting borrow pits impacted the fresh-water aquifer. In the low areas of...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 1: Bill_%26_Melinda_Gates_Foundation (paragraph 6)\n",
            "The IJM used the grant money to found \"Project Lantern\" and established an office in the Philippines city of Cebu. In 2010 the results of the project were published, in which the IJM stated that Project Lantern had led to \"an increase in law enforcement activity in sex trafficking cases, an increase...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 2: Genome (paragraph 8)\n",
            "Whereas a genome sequence lists the order of every DNA base in a genome, a genome map identifies the landmarks. A genome map is less detailed than a genome sequence and aids in navigating around the genome. The Human Genome Project was organized to map and to sequence the human genome. A fundamental...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 3: Rajasthan (paragraph 9)\n",
            "The Aravalli Range and the lands to the east and southeast of the range are generally more fertile and better watered. This region is home to the Kathiarbar-Gir dry deciduous forests ecoregion, with tropical dry broadleaf forests that include teak, Acacia, and other trees. The hilly Vagad region, ho...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 4: Near_East (paragraph 57)\n",
            "One such institution is the Centre for the Study of Ancient Documents (CSAD) founded by and located centrally at Oxford University, Great Britain. Among its many activities CSAD numbers \"a long-term project to create a library of digitised images of Greek inscriptions.\" These it arranges by region. ...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "================================================================================\n",
            "QUESTION ID: 4\n",
            "Question: How many satellites in the Beidou-1 constellation?\n",
            "================================================================================\n",
            "\n",
            "Rank 0: Association_football (paragraph 2)\n",
            "Association football in itself does not have a classical history. Notwithstanding any similarities to other ball games played around the world FIFA have recognised that no historical connection exists with any game played in antiquity outside Europe. The modern rules of association football are base...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 1: Bras%C3%ADlia (paragraph 8)\n",
            "Both low-cost and luxury housing were built by the government in the Brasília. The residential zones of the inner city are arranged into superquadras (\"superblocks\"): groups of apartment buildings along with a prescribed number and type of schools, retail stores, and open spaces. At the northern end...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 2: Saint_Helena (paragraph 64)\n",
            "Radio St Helena, which started operations on Christmas Day 1967, provided a local radio service that had a range of about 100 km (62 mi) from the island, and also broadcast internationally on shortwave radio (11092.5 kHz) on one day a year. The station presented news, features and music in collabora...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 3: Dog (paragraph 52)\n",
            "Dog meat is consumed in some East Asian countries, including Korea, China, and Vietnam, a practice that dates back to antiquity. It is estimated that 13–16 million dogs are killed and consumed in Asia every year. Other cultures, such as Polynesia and pre-Columbian Mexico, also consumed dog meat in t...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 4: Nanjing (paragraph 54)\n",
            "Nanjing has some of the oldest and finest museums in China. Nanjing Museum, formerly known as National Central Museum during ROC period, is the first modern museum and remains as one of the leading museums in China having 400,000 items in its permanent collection,. The museum is notable for enormous...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "================================================================================\n",
            "QUESTION ID: 7\n",
            "Question: When did Beyoncé  receive ten nominations for the Grammy Awards?\n",
            "================================================================================\n",
            "\n",
            "Rank 0: Czech_language (paragraph 21)\n",
            "Czech distinguishes three genders—masculine, feminine, and neuter—and the masculine gender is subdivided into animate and inanimate. With few exceptions, feminine nouns in the nominative case end in -a, -e, or -ost; neuter nouns in -o, -e, or -í, and masculine nouns in a consonant. Adjectives agree ...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 1: The_Blitz (paragraph 4)\n",
            "Within the Luftwaffe, there was a more muted view of strategic bombing. The OKL did not oppose the strategic bombardment of enemy industries and or cities, and believed it could greatly affect the balance of power on the battlefield in Germany's favour by disrupting production and damaging civilian ...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 2: Dominican_Order (paragraph 35)\n",
            "Because the nuns of the order did not preach among the people, the need to engage in study was not as immediate or intense as it was for men. They did participate, however, in a number of intellectual activities. Along with sewing and embroidery, nuns often engaged in reading and discussing correspo...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 3: High-definition_television (paragraph 11)\n",
            "The limited standardization of analog HDTV in the 1990s did not lead to global HDTV adoption as technical and economic constraints at the time did not permit HDTV to use bandwidths greater than normal television....\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 4: Translation (paragraph 22)\n",
            "Throughout the 18th century, the watchword of translators was ease of reading. Whatever they did not understand in a text, or thought might bore readers, they omitted. They cheerfully assumed that their own style of expression was the best, and that texts should be made to conform to it in translati...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "================================================================================\n",
            "QUESTION ID: 10\n",
            "Question: With which goddess did Sulla, Pompey, and Julius Caesar all claim a special relationship?\n",
            "================================================================================\n",
            "\n",
            "Rank 0: Symbiosis (paragraph 8)\n",
            "An example of mutual symbiosis is the relationship between the ocellaris clownfish that dwell among the tentacles of Ritteri sea anemones. The territorial fish protects the anemone from anemone-eating fish, and in turn the stinging tentacles of the anemone protect the clownfish from its predators. A...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 1: Education (paragraph 26)\n",
            "Educational psychology can in part be understood through its relationship with other disciplines. It is informed primarily by psychology, bearing a relationship to that discipline analogous to the relationship between medicine and biology. Educational psychology in turn informs a wide range of speci...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 2: Arnold_Schwarzenegger (paragraph 69)\n",
            "Schwarzenegger met his next paramour, Sue Moray, a Beverly Hills hairdresser's assistant, on Venice Beach in July 1977. According to Moray, the couple led an open relationship: \"We were faithful when we were both in LA … but when he was out of town, we were free to do whatever we wanted.\" Schwarzene...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 3: Josip_Broz_Tito (paragraph 52)\n",
            "His next relationship was with Herta Haas, whom he married in 1940. Broz left for Belgrade after the April War, leaving Haas pregnant. In May 1941, she gave birth to their son, Aleksandar \"Mišo\" Broz. All throughout his relationship with Haas, Tito had maintained a promiscuous life and had a paralle...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 4: Unicode (paragraph 18)\n",
            "Many scripts, including Arabic and Devanagari, have special orthographic rules that require certain combinations of letterforms to be combined into special ligature forms. The rules governing ligature formation can be quite complex, requiring special script-shaping technologies such as ACE (Arabic C...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "================================================================================\n",
            "QUESTION ID: 13\n",
            "Question: What area is considered to have a desert climate despite having an annual monsoon season?\n",
            "================================================================================\n",
            "\n",
            "Rank 0: Mali (paragraph 10)\n",
            "Mali lies in the torrid zone and is among the hottest countries in the world. The thermal equator, which matches the hottest spots year-round on the planet based on the mean daily annual temperature, crosses the country. Most of Mali receives negligible rainfall and droughts are very frequent. Late ...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 1: San_Diego (paragraph 16)\n",
            "San Diego is one of the top-ten best climates in the Farmers' Almanac and is one of the two best summer climates in America as scored by The Weather Channel. Under the Köppen–Geiger climate classification system, the San Diego area has been variously categorized as having either a semi-arid climate ...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 2: Chihuahua_(state) (paragraph 39)\n",
            "The plains at the foot of the Sierra Madre Occidental is an elongated mesa known as Altiplanicie Mexicana that exhibits a steppe climate and serves as a transition zone from the mountain climate in the western part of the state to the desert climate in the eastern side of the state. The steppe zone ...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 3: Alaska (paragraph 8)\n",
            "The climate in Southeast Alaska is a mid-latitude oceanic climate (Köppen climate classification: Cfb) in the southern sections and a subarctic oceanic climate (Köppen Cfc) in the northern parts. On an annual basis, Southeast is both the wettest and warmest part of Alaska with milder temperatures in...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 4: American_Idol (paragraph 8)\n",
            "Guest judges may occasionally be introduced. In season two, guest judges such as Lionel Richie and Robin Gibb were used, and in season three Donna Summer, Quentin Tarantino and some of the mentors also joined as judges to critique the performances in the final rounds. Guest judges were used in the a...\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "questions_df = pd.read_csv('questions.tsv', sep='\\t', encoding='utf-8')\n",
        "matches_df = pd.read_csv('question-matches.tsv', sep='\\t', encoding='utf-8')\n",
        "parsed_df = pd.read_csv('parsed.tsv', sep='\\t', encoding='utf-8')\n",
        "\n",
        "# Get first 5 questions sorted by question_id\n",
        "first_5_questions = questions_df.sort_values('question_id').head(5)\n",
        "\n",
        "# Review matches for each question\n",
        "for _, question_row in first_5_questions.iterrows():\n",
        "    q_id = question_row['question_id']\n",
        "    question_text = question_row['question']\n",
        "    \n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"QUESTION ID: {q_id}\")\n",
        "    print(f\"Question: {question_text}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "    \n",
        "    # Get top 5 matches for this question\n",
        "    question_matches = matches_df[matches_df['question_id'] == q_id].sort_values('question_rank')\n",
        "    \n",
        "    for _, match in question_matches.iterrows():\n",
        "        rank = match['question_rank']\n",
        "        doc_title = match['document_title']\n",
        "        para_idx = match['paragraph_index']\n",
        "        \n",
        "        # Get the paragraph text\n",
        "        paragraph = parsed_df[\n",
        "            (parsed_df['document_title'] == doc_title) & \n",
        "            (parsed_df['paragraph_index'] == para_idx)\n",
        "        ]['paragraph_context'].values[0]\n",
        "        \n",
        "        print(f\"Rank {rank}: {doc_title} (paragraph {para_idx})\")\n",
        "        print(f\"{paragraph[:300]}...\")\n",
        "        print(f\"{'-'*80}\\n\")\n",
        "\n",
        "# After reviewing above, manually fill in the worst matches\n",
        "worst_paragraphs = [\n",
        "    {'question_id': '1', 'Genome': 'Title1', 'paragraph_index': 9},\n",
        "    {'question_id': '4', 'document_title': 'Association_football', 'paragraph_index': 2},\n",
        "    {'question_id': '7', 'document_title': 'High-definiton_telivision', 'paragraph_index': 11},\n",
        "    {'question_id': '10', 'document_title': 'Education', 'paragraph_index': 26},\n",
        "    {'question_id': '13', 'document_title': 'American_Idol', 'paragraph_index': 8},\n",
        "]\n",
        "\n",
        "worst_df = pd.DataFrame(worst_paragraphs)\n",
        "worst_df.to_csv('worst-paragraphs.tsv', sep='\\t', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FqfB5lZ087m"
      },
      "source": [
        "Submit \"worst-paragraphs.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHaFK8Z10xnS"
      },
      "source": [
        "Write a file \"worst-paragraphs.tsv\" with three columns question_id, document_title, paragraph_index."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smsTLuFcvR-I"
      },
      "source": [
        "## Part 7: Code\n",
        "\n",
        "Please submit a Jupyter notebook that can reproduce all your calculations and recreate the previously submitted files.\n",
        "You do not need to provide code for data collection if you did that by manually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi8lV2pbvWMs"
      },
      "source": [
        "## Part 8: Acknowledgements\n",
        "\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you did this assignment completely on your own, simply write none below.\n",
        "\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for. If you did not use any other libraries, simply write none below.\n",
        "\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy. If you did not use any generative AI tools, simply write none below."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
